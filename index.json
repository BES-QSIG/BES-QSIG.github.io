[
  {
    "authors": [
      "Laura Graham"
    ],
    "categories": [],
    "content": "We have migrated from our old Wordpress site in order to keep everything in one place. Our Wordpress site will function as an archive, but new material will be updated here.\nOur aim as a group is to:\n Support quantitative skills development for all ecologists Improve dissemination of new quantitative methods to their users Provide a forum to advance quantitative ecology in its own right  If you have ideas for events, workshops or courses that you would like to see us organise (or would like to organise yourself with our support), please contact us.\n",
    "date": 1543276800,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1543276800,
    "objectID": "6c2e4b1cbfc388c512d2100ea72573f4",
    "permalink": "https://BES-QSIG.github.io/post/welcome-to-new-site/",
    "publishdate": "2018-11-27T00:00:00Z",
    "relpermalink": "/post/welcome-to-new-site/",
    "section": "post",
    "summary": "We have migrated from our old Wordpress site in order to keep everything in one place. Our Wordpress site will function as an archive, but new material will be updated here.\nOur aim as a group is to:\n Support quantitative skills development for all ecologists Improve dissemination of new quantitative methods to their users Provide a forum to advance quantitative ecology in its own right  If you have ideas for events, workshops or courses that you would like to see us organise (or would like to organise yourself with our support), please contact us.",
    "tags": [],
    "title": "Welcome to the new Quantitative Ecology Blog",
    "type": "post"
  },
  {
    "authors": null,
    "categories": null,
    "content": " Getting here Pre-course Instructions This is where the installation stuff needs to go.\n",
    "date": 1542672000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1542672000,
    "objectID": "39724aa346816c4a351e7ab91ab0b55d",
    "permalink": "https://BES-QSIG.github.io/courses/advancingr/",
    "publishdate": "2018-11-20T00:00:00Z",
    "relpermalink": "/courses/advancingr/",
    "section": "courses",
    "summary": "Getting here Pre-course Instructions This is where the installation stuff needs to go.",
    "tags": null,
    "title": "Advancing Your R",
    "type": "docs"
  },
  {
    "authors": null,
    "categories": null,
    "content": " PART I: Create a reproducible report using Markdown 1. What is R Markdown? R Markdown allows you to create documents that serve as a neat record of your analysis. In the world of reproducible research, we want other researchers to easily understand what we did in our analysis. You might choose to create an R markdown document as an appendix to a paper or project assignment that you are doing, upload it to an online repository such as Github, or simply to keep as a personal record so you can quickly look back at your code and see what you did. R Markdown presents your code alongside its output (graphs, tables, etc.) with conventional text to explain it, a bit like a notebook. Your report can also be what you base your future methods and results sections in your manuscripts, thesis chapters, etc.\nR Markdown uses markdown syntax. Markdown is a very simple \u0026lsquo;markup\u0026rsquo; language which provides methods for creating documents with headers, images, links etc. from plain text files, while keeping the original plain text file easy to read. You can convert Markdown documents to other file types like .html or .pdf.\n \n2. Download R Markdown To get R Markdown working in RStudio, the first thing you need is the rmarkdown package, which you can get from CRAN by running the following commands in R or RStudio:\ninstall.packages(\u0026quot;rmarkdown\u0026quot;) library(rmarkdown)  3. The different parts of an R Markdown file The YAML Header At the top of any R Markdown script is a YAML header section enclosed by ---. By default this includes a title, author, date and the file type you want to output to. Many other options are available for different functions and formatting, see here for .html options and here for .pdf options. Rules in the header section will alter the whole document.\nAdd your own details at the top of your.Rmd script, e.g.:\n--- title: \u0026quot;The tidyverse in action - population change in forests\u0026quot; author: Gergana Daskalova date: 22/Oct/2016 output: html_document ---  By default, the title, author, date and output format are printed at the top of your .html document.\nNow that we have our first piece of content, we can test the .Rmd file by compiling it to .html. To compile your .Rmd file into a .html document, you should press the Knit button in the taskbar:\nNot only does a preview appear in the Viewer window in RStudio, but it also saves a .html file to the same folder where you saved your .Rmd file.\n\nCode Chunks Have a read through the text below to learn a bit more about how Markdown works and then you can start compiling the rest of your .Md file.\nThe setup chunk This code chunk appears in .Md files in R by default, it won\u0026rsquo;t appear in your html or pdf document, it just sets up the document.\n```{r setup, include = FALSE} knitr::opts_chunk$set(echo = TRUE) ```  The rest of the code chunks This is where you can add your own code, accompanying explanation and any outputs. Code that is included in your .Rmd document should be enclosed by three backwards apostrophes ``` (grave accents!). These are known as code chunks and look like this (no need to copy this, just an example):\n```{r} norm \u0026lt;- rnorm(100, mean = 0, sd = 1) ```  Inside the curly brackets is a space where you can assign rules for that code chunk. The code chunk above says that the code is R code.\nIt\u0026rsquo;s important to remember when you are creating an R Markdown file that if you want to run code that refers to an object, for example:\n```{r} plot(dataframe) ```  You have to include the code that defines what dataframe is, just like in a normal R script. For example:\n```{r} A \u0026lt;- c(\u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;) B \u0026lt;- c(5, 10, 15, 20) dataframe \u0026lt;- data.frame(A, B) plot(dataframe) ```  Or if you are loading a dataframe from a .csv file, you must include the code in the .Rmd:\n```{r} dataframe \u0026lt;- read.csv(\u0026quot;~/Desktop/Code/dataframe.csv\u0026quot;) ```  Similarly, if you are using any packages in your analysis, you have to load them in the .Rmd file using library() like in a normal R script.\n```{r} library(dplyr) ```  Hiding code chunks If you don\u0026rsquo;t want the code of a particular code chunk to appear in the final document, but still want to show the output (e.g. a plot), then you can include echo = FALSE in the code chunk instructions.\n```{r, echo = FALSE} A \u0026lt;- c(\u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;) B \u0026lt;- c(5, 10, 15, 20) dataframe \u0026lt;- data.frame(A, B) plot(dataframe) ```  Sometimes, you might want to create an object, but not include both the code and its output in the final .html file. To do this you can use, include = FALSE. Be aware though, when making reproducible research it\u0026rsquo;s often not a good idea to completely hide some part of your analysis:\nREMEMBER: R Markdown doesn\u0026rsquo;t pay attention to anything you have loaded in other R scripts, you have to load all objects and packages in the R Markdown script.\nNow you can start copying across the code from your tidyverse script and insert it into a code chunk in your .Rmd document. Better not to do it all at once, you can start with the first parts of the tidyverse script and gradually add on more after you\u0026rsquo;ve seen what the .Rmd output looks like.\nYou can run an individual chunk of code at any time by placing your cursor inside the code chunk and selecting Run -\u0026gt; Run Current Chunk:\nSummary of code chunk instructions .tg {border-collapse:collapse;border-spacing:0;} .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;} .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;} .tg .tg-yw4l{vertical-align:top}   Rule Example\n(default) Function   eval eval=TRUE Is the code run and the results included in the output?   include include=TRUE Are the code and the results included in the output?   echo echo=TRUE Is the code displayed alongside the results?   warning warning=TRUE Are warning messages displayed?   error error=FALSE Are error messages displayed?   message message=TRUE Are messages displayed?   tidy tidy=FALSE Is the code reformatted to make it look “tidy”?   results results=\u0026ldquo;markup\u0026rdquo;  How are results treated?  \u0026ldquo;hide\u0026rdquo; = no results \u0026ldquo;asis\u0026rdquo; = results without formatting \u0026ldquo;hold\u0026rdquo; = results only compiled at end of chunk (use if many commands act on one object)   cache cache=FALSE Are the results cached for future renders?   comment comment=\u0026ldquo;##\u0026rdquo; What character are comments prefaced with?   fig.width, fig.height fig.width=7 What width/height (in inches) are the plots?   fig.align fig.align=\u0026ldquo;left\u0026rdquo; \u0026ldquo;left\u0026rdquo; \u0026ldquo;right\u0026rdquo; \u0026ldquo;center\u0026rdquo;  \n4. Inserting Figures By default, RMarkdown will place graphs by maximising their height, while keeping them within the margins of the page and maintaining aspect ratio. If you have a particularly tall figure, this can mean a really huge graph. To manually set the figure dimensions, you can insert an instruction into the curly braces:\n```{r, fig.width = 2.5, fig.height = 7.5} ggplot(df, aes(x = x, y = y) + geom_point() ```  5. Inserting Tables R Markdown can print the contents of a data frame easily by enclosing the name of the data frame in a code chunk:\n```{r} dataframe ```  This can look a bit messy, especially with data frames with a lot of columns. You can also use a table formatting function, e.g. kable() from the knitr package. The first argument tells kable to make a table out of the object dataframe and that numbers should have two significant figures. Remember to load the knitr package in your .Rmd file, if you are using the kable() function.\n```{r} kable(dataframe, digits = 2) ```  If you want a bit more control over the content of your table you can use pander() from the pander package. Imagine I want the 3rd column to appear in italics:\n```{r} emphasize.italics.cols(3) # Make the 3rd column italics pander(richness_abund) # Create the table ```  Now that you have started your Markdown document, you can use that when completing the next part of the tutorial, i.e., inserting the code that follows into code chunks and then generating a report at the end of this tutorial.\nPART II: Analyse and visualise data using the tidyverse Learning Objectives 1. Intro to the tidyverse How to analyse population change of forest vertebrates  How to write a custom ggplot2 function How to use gather() and spread() from the tidyr package How to parse numbers using parse_number() from the readr package How to use the distinct() function from dplyr How to use the filter() function from dplyr How to use the mutate() function from dplyr How to use the summarise()/summarize() function from dplyr How to use the tidy() function from the broom package to summarise model results How to use the select() function from dplyr  In this tutorial, we will focus on how to efficiently format, manipulate and visualise large datasets. We will use the tidyr and dplyr packages to clean up data frames and calculate new variables. We will use the broom and purr packages to make the modelling of thousands of population trends more efficient. We will use the ggplot2 package to make graphs, maps of occurrence records, and to visualise ppulation trends and then we will arrange all of our graphs together using the gridExtra package.\nWe will be working with population data from the Living Planet Database and red deer occurrence data from the Global Biodiversity Information Facility, both of which are publicly available datasets.\nFirst, we will model population change for vertebrate forest species to see whether greater population change is found for longer duration studies.\nBecause we have created a version-controlled R project using the repository for the workshop, we are already in the right working directory, i.e. the folder that contains all the data and other files, thus there is no need for us to set a working directory at the start of the script, unless we explicitly want to change it for some reason.\nHere are the packages we need. Note that not all tidyverse packages load automatically with library(tidyverse) - only the core ones do, so you need to load broom separately. If you don\u0026rsquo;t have some of the packages installed, you can install them using ìnstall.packages(\u0026quot;package-name\u0026quot;).\n# Packages ---- library(tidyverse) # Hadley Wickham's tidyverse - the theme of this tutorial library(broom) # To summarise model outputs library(ggExtra) # To make pretty graphs - addon package to ggplot2 library(maps) # To make pretty maps - warning: maps masks map from purr! library(RColorBrewer) # To make pretty colours library(gridExtra) # To arrange multi-plot panels  If you\u0026rsquo;ve ever tried to perfect your ggplot2 graphs, you might have noticed that the lines starting with theme() quickly pile up: you adjust the font size of the axes and the labels, the position of the title, the background colour of the plot, you remove the grid lines in the background, etc. And then you have to do the same for the next plot, which really increases the amount of code you use. Here is a simple solution: create a customised theme that combines all the theme() elements you want and apply it to your graphs to make things easier and increase consistency. You can include as many elements in your theme as you want, as long as they don\u0026rsquo;t contradict one another and then when you apply your theme to a graph, only the relevant elements will be considered - e.g. for our graphs we won\u0026rsquo;t need to use legend.position, but it\u0026rsquo;s fine to keep it in the theme in case any future graphs we apply it to do have the need for legends.\n# Setting a custom ggplot2 function --- # *** Functional Programming *** # This function makes a pretty ggplot theme # This function takes no arguments! theme_LPD \u0026lt;- function(){ theme_bw()+ theme(axis.text.x = element_text(size = 12, vjust = 1, hjust = 1), axis.text.y = element_text(size = 12), axis.title.x = element_text(size = 14, face = \u0026quot;plain\u0026quot;), axis.title.y = element_text(size = 14, face = \u0026quot;plain\u0026quot;), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(), panel.grid.major.y = element_blank(), plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), units = , \u0026quot;cm\u0026quot;), plot.title = element_text(size = 20, vjust = 1, hjust = 0.5), legend.text = element_text(size = 12, face = \u0026quot;italic\u0026quot;), legend.title = element_blank(), legend.position = c(0.5, 0.8)) }  Load population trend data The data are in a .RData format, as those are quicker to use, since .Rdata files are more compressed. Of course, a drawback is that .RData files can only be used within R, whereas .csv files are more transferable.\n# Load data ---- load(\u0026quot;LPDdata_Feb2016.RData\u0026quot;) # Inspect data ---- head(LPDdata_Feb2016)   \nAt the moment, each row contains a population that has been monitored over time and towards the right of the data frame there are lots of columns with population estimates for each year. To make this data \u0026ldquo;tidy\u0026rdquo; (one column per variable) we can use gather() to transform the data so there is a new column containing all the years for each population and an adjacent column containing all the population estimates for those years.\nThis takes our original dataset LPIdata_Feb2016 and creates a new column called year, fills it with column names from columns 26:70 and then uses the data from these columns to make another column called pop.\n# Format data for analysis ---- # Transform from wide to long format usign gather (opposite is spread) # *** gather() function from the dplyr package in the tidyverse *** LPD_long \u0026lt;- gather(data = LPDdata_Feb2016, key = \u0026quot;year\u0026quot;, value = \u0026quot;pop\u0026quot;, select = 26:70)  Because column names are coded in as characters, when we turned the column names (1970, 1971, 1972, etc.) into rows, R automatically put an X in front of the numbers to force them to remain characters. We don\u0026rsquo;t want that, so to turn year into a numeric variable, use the parse_number() function from the readr package. We can also make all the column names lowercase and remove some of the funky characters in the country column - strange characters mess up things in general, e.g. when you want to save files, push them to GitHub, etc.\n# Get rid of the X in front of years # *** parse_number() from the readr package in the tidyverse *** LPD_long$year \u0026lt;- parse_number(LPD_long$year) # Rename variable names for consistency names(LPD_long) names(LPD_long) \u0026lt;- tolower(names(LPD_long)) names(LPD_long) # Create new column with genus and species together LPD_long$species.name \u0026lt;- paste(LPD_long$genus, LPD_long$species, sep = \u0026quot; \u0026quot;) # Get rid of strange characters like \u0026quot; / \u0026quot; LPD_long$country.list \u0026lt;- gsub(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;, LPD_long$country.list, fixed = TRUE) LPD_long$biome \u0026lt;- gsub(\u0026quot;/\u0026quot;, \u0026quot;\u0026quot;, LPD_long$biome, fixed = TRUE) # Examine the tidy data frame head(LPD_long)   \nNow that our dataset is tidy we can get it ready for our analysis. We want to only use populations that have more than 5 years of data to make sure our analysis has enough data to capture population change. We should also scale the population data, because since the data come from many species, the units and magnitude of the data are very different - imagine tiny fish whose abundance is in the millions, and large carnivores whose abundance is much smaller. Scaling also normalises the data, as later on we will be using linear models assuming a normal distribution. To do all of this in one go, we can use pipes.\nPipes (%\u0026gt;%) are a way of streamlining data manipulation - imagine all of your data coming in one end of the pipe, while they are in there, they are manipulated, summarised, etc., then the output (e.g. your new data frame or summary statistics) comes out the other end of the pipe. At each step of the pipe processing, the pipe is using the ouput of the previous step.\n# Data manipulation ---- # *** piping from from dplyr LPD_long2 \u0026lt;- LPD_long %\u0026gt;% # Remove duplicate rows # *** distinct() function from dplyr distinct(LPD_long) %\u0026gt;% # remove NAs in the population column # *** filter() function from dplyr filter(is.finite(pop)) %\u0026gt;% # Group rows so that each group is one population # *** group_by() function from dplyr group_by(id) %\u0026gt;% # Make some calculations # *** mutate() function from dplyr mutate(maxyear = max(year), minyear = min(year), # Calculate duration duration = maxyear - minyear, # Scale population trend data scalepop = (pop - min(pop))/(max(pop) - min(pop))) %\u0026gt;% # Keep populations with \u0026gt;5 years worth of data and calculate length of monitoring filter(is.finite(scalepop), length(unique(year)) \u0026gt; 5) %\u0026gt;% # Remove any groupings you've greated in the pipe ungroup()  Now we can explore our data a bit. Let\u0026rsquo;s create a few basic summary statistics for each biome and store them in a new data frame:\n# Calculate summary statistics for each biome LPD_biome_sum \u0026lt;- LPD_long2 %\u0026gt;% # Group by biome group_by(biome) %\u0026gt;% # Create columns, number of populations # *** summarise()/summarize() function from dplyr in the tidyverse *** summarise(populations = n(), # Calculate the mean study length mean_study_length_years = mean(duration), # Model sampling method dominant_sampling_method = names(which.max(table(sampling.method))), # Model unit type dominant_units = names(which.max(table(units)))) %\u0026gt;% # Remove any groupings you've greated in the pipe ungroup() # Take a look at some of the records head(LPD_biome_sum)  Next we will explore how populations from two of these biomes, temperate coniferous and temperate broadleaf forests, have changed over the monitoring duration. We will make the biome variable a factor (before it is just a character variable), so that later on we can make graphs based on the two categories (coniferous and broadleaf forests). We\u0026rsquo;ll use the filter() function from dplyr to subset the data to just the forest species.\n# Subset to just temperate forest species ----- # Notice the difference between | and \u0026amp; when filtering # | is an \u0026quot;or\u0026quot; whereas \u0026amp; is \u0026quot;and\u0026quot;, i.e. both conditions have to be met # at the same time LPD_long2$biome \u0026lt;- as.factor(LPD_long2$biome) LPD.forest \u0026lt;- filter(LPD_long2, biome == \u0026quot;Temperate broadleaf and mixed forests\u0026quot; | biome == \u0026quot;Temperate coniferous forests\u0026quot;)  Before running models, it\u0026rsquo;s a good idea to visualise our data to explore what kind of distribution we are working with.\nThe gg in ggplot2 stands for grammar of graphics. Writing the code for your graph is like constructing a sentence made up of different parts that logically follow from one another. In a data visualisation context, the different elements of the code represent layers - first you make an empty plot, then you add a layer with your data points, then your measure of uncertainty, the axis labels and so on.\n When using ggplot2, you usually start your code with ggplot(your_data, aes(x = independent_variable, y = dependent_variable)), then you add the type of plot you want to make using + geom_boxplot(), + geom_histogram(), etc. aes stands for aesthetics, hinting to the fact that using ggplot2 you can make aesthetically pleasing graphs - there are many ggplot2 functions to help you clearly communicate your results, and we will now go through some of them.\nWhen we want to change the colour, shape or fill of a variable based on another variable, e.g. colour-code by species, we include colour = species inside the aes() function. When we want to set a specific colour, shape or fill, e.g. colour = \u0026quot;black\u0026quot;, we put that outside of the aes() function.\nWe will see our custom theme theme_LPD() in action as well!\n# Data visualisation ---- # Data distribution - a histogram (forest.hist \u0026lt;- ggplot(LPD.forest, aes(x = scalepop)) + geom_histogram(aes(fill = biome), position = \u0026quot;identity\u0026quot;, colour = \u0026quot;grey40\u0026quot;) + geom_vline(aes(xintercept = mean(scalepop)), # Adding a line for mean abundance colour = \u0026quot;darkred\u0026quot;, linetype = \u0026quot;dashed\u0026quot;, size = 1) + scale_fill_manual(values = c(\u0026quot;#66CD00\u0026quot;, \u0026quot;#53868B\u0026quot;)) + theme_LPD() + labs(title = \u0026quot;a) Data distribution\\n\u0026quot;) + guides(fill = F)) # Hiding the legend - this will be a two plot panel # thus we don't need the same legend twice  Next up we can explore for how long populations have been monitored in the two biomes using a density histogram.\n# Density histogram of duration of studies in the two biomes (duration.forests \u0026lt;- ggplot(LPD.forest, aes(duration, colour = biome)) + stat_density(geom = \u0026quot;line\u0026quot;, size = 2, position = \u0026quot;identity\u0026quot;) + theme_LPD() + scale_colour_manual(values = c(\u0026quot;#66CD00\u0026quot;, \u0026quot;#53868B\u0026quot;)) + labs(x = \u0026quot;\\nYears\u0026quot;, y = \u0026quot;Density\\n\u0026quot;, title = \u0026quot;b) Monitoring duration\\n\u0026quot;))  We\u0026rsquo;ll use the grid.arrange function from the gridExtra package to combine the two plots in a panel. You can specify the number of columns using ncol = and the number of rows using nrow =.\n# Arrange in a panel and save forest.panel \u0026lt;- grid.arrange(forest.hist, duration.forests, ncol = 2) ggsave(forest.panel, file = \u0026quot;forest_panel.png\u0026quot;, height = 5, width = 10)   \nWe are now ready to model how each population has changed over time. There are 1785 populations, so with this one code chunk, we will run 1785 models and tidy up their outputs. You can read through the line-by-line comments to get a feel for what each line of code is doing.\nOne specific thing to note is that when you add the lm() function in a pipe, you have to add data = ., which means use the outcome of the previous step in the pipe for the model.\n# Calculate population change for each forest population # 1785 models in one go! # Using a pipe forest.slopes \u0026lt;- LPD.forest %\u0026gt;% # Group by the key variables that we want to interate over group_by(decimal.latitude, decimal.longitude, class, species.name, id, duration, location.of.population) %\u0026gt;% # Create a linear model for each group do(mod = lm(scalepop ~ year, data = .)) %\u0026gt;% # Extract model coefficients using tidy() from the # *** tidy() function from the broom package *** tidy(mod) %\u0026gt;% # Filter out slopes and remove intercept values filter(term == \u0026quot;year\u0026quot;) %\u0026gt;% # Get rid of the column term as we don't need it any more # *** select() function from dplyr in the tidyverse *** dplyr::select(-term) %\u0026gt;% # Remove any groupings you've greated in the pipe ungroup()  We are ungrouping at the end of our pipe just because otherwise the object remains grouped and later on that might cause problems, if we forget about it.\nNow we can visualise the outputs of all our models and see how they vary based on study duration. We will add density histograms along the margins of the graph which makes for a more informative graph using the ggMarginal() function from the ggExtra package. Note that ggExtra is also an addin in RStudio, so for future reference, if you select some ggplot2 code, then click on Addins/ggplot2 Marginal plots (the menu is in the middle top part of the screen), you can customise marginal histograms and the code gets automatically generated.\n# Visualising model outputs ---- # Plotting slope estimates and standard errors for all populations and adding histograms along the margins (all.slopes \u0026lt;- ggplot(forest.slopes, aes(x = duration, y = estimate)) + geom_pointrange(aes(ymin = estimate - std.error, ymax = estimate + std.error), alpha = 0.3, size = 0.3) + geom_hline(yintercept = 0, linetype = \u0026quot;dashed\u0026quot;) + theme_LPD() + ylab(\u0026quot;Population change\\n\u0026quot;) + xlab(\u0026quot;\\nDuration (years)\u0026quot;)) (density.slopes \u0026lt;- ggExtra::ggMarginal( p = all.slopes, type = 'density', margins = 'both', size = 5, col = 'gray40', fill = 'gray' )) # Save the plot ggsave(density.slopes, filename = \u0026quot;slopes_duration.png\u0026quot;, height = 6, width = 6)   \n\n2. Using pipes to make figures with large datasets How to print plots of population change for multiple taxa\n How to set up file paths and folders in R How to use a pipe to plot many plots by taxa How to use the purrr package and functional programming  In the next part of the tutorial, we will focus on automating iterative actions, for example when we want to create the same type of graph for different subsets of our data. In our case, we will make histograms of the population change experienced by different vertebrate taxa in forests. When making multiple graphs at once, we have to specify the folder where they will be saved first:\n# PART 2: Using pipes to make figures with large datasets ---- # Make histograms of slope estimates for each taxa ----- # Set up new folder for figures # Set path to relevant path on your computer/in your repository path1 \u0026lt;- \u0026quot;Taxa_Forest_LPD/\u0026quot; # Create new folder dir.create(path1)  There isn\u0026rsquo;t a right answer here, there are different ways to achieve the same result and you can decide which one works best for your workflow. First we will use dplyr and pipes %\u0026gt;%. Since we want one graph per taxa, we are going to group by the class variable. You can add functions that are not part of the dplyr package to pipes using do - in our case, we are saying that we want R to do our requested action (making and saving the histograms) for each taxa.\n# First we will do this using dplyr and a pipe forest.slopes %\u0026gt;% # Select the relevant data dplyr::select(id, class, species.name, estimate) %\u0026gt;% # Group by taxa group_by(class) %\u0026gt;% # Save all plots in new folder do(ggsave(ggplot(., aes(x = estimate)) + # Add histograms geom_histogram(colour = \u0026quot;darkgreen\u0026quot;, fill = \u0026quot;darkgreen\u0026quot;, binwidth = 0.02) + # Use custom theme theme_LPD() + # Add axis lables xlab(\u0026quot;Rate of population change (slopes)\u0026quot;), # Set up file names to print to filename = gsub(\u0026quot;\u0026quot;, \u0026quot;\u0026quot;, paste0(path1, unique(as.character(.$class)), \u0026quot;.pdf\u0026quot;)), device = \u0026quot;pdf\u0026quot;))  A warning message pops up: Error: Results 1, 2, 3, 4 must be data frames, not NULL - you can ignore this, it\u0026rsquo;s because the do() function expects a data frame as an output, but in our case we are making graphs, not data frames.\nIf you go check out your folder now, you should see four histograms, one per taxa:  \nAnother way to make all those histograms in one go is by creating a function for it. In general, whenever you find yourself copying and pasting lots of code only to change the object name, you\u0026rsquo;re probably in a position to swap all the code with a function - you can then apply the function using the purrr package.\nBut what is purrr? It is a way to \u0026ldquo;map\u0026rdquo; or \u0026ldquo;apply\u0026rdquo; functions to data. Note that there are functions from other packages also called map(), which is why we are specifying we want the map() function from the purrr package. Here we will first format the data taxa.slopes and then we will map it to the mean fuction:\nWe have to change the format of the data, in our case we will split the data using spread() from the tidyr package.\n# Here we select the relevant data # Let's get rid of the other levels of 'class' forest.slopes$class \u0026lt;- as.character(forest.slopes$class) # Selecting the relevant data and splitting it into a list taxa.slopes \u0026lt;- forest.slopes %\u0026gt;% dplyr::select(id, class, estimate) %\u0026gt;% spread(class, estimate) %\u0026gt;% dplyr::select(-id)  We can apply the mean function using purrr::map():\ntaxa.mean \u0026lt;- purrr::map(taxa.slopes, ~mean(., na.rm = TRUE)) # This plots the mean population change per taxa taxa.mean  Now we can write our own function to make histograms and use the purrr package to apply it to each taxa.\n### Intro to the purrr package ---- # First let's write a function to make the plots # *** Functional Programming *** # This function takes one argument x, the data vector that we want to make a histogram plot.hist \u0026lt;- function(x) { ggplot() + geom_histogram(aes(x), colour = \u0026quot;darkgreen\u0026quot;, fill = \u0026quot;darkgreen\u0026quot;, binwidth = 0.02) + theme_LPD() + xlab(\u0026quot;Rate of population change (slopes)\u0026quot;) }  Now we can use purr to \u0026ldquo;map\u0026rdquo; our figure making function. The first input is your data that you want to iterate over and the second input is the function.\ntaxa.plots \u0026lt;- purrr::map(taxa.slopes, ~plot.hist(.)) # We need to make a new folder to put these figures in path2 \u0026lt;- \u0026quot;Taxa_Forest_LPD_purrr/\u0026quot; dir.create(path2)  First we learned about map() when there is one dataset, but there are other purrr functions,too. walk2() takes two arguments and returns nothing. In our case we just want to print the graphs, so we don\u0026rsquo;t need anything returned. The first argument is our file path, the second is our data and ggsave is our function.\n# *** walk2() function in purrr from the tidyverse *** walk2(paste0(path2, names(taxa.slopes), \u0026quot;.pdf\u0026quot;), taxa.plots, ggsave)  \n3. Downloading and mapping data from large datasets Map the distribution of a forest vertebrate species and the location of monitored populations  How to download GBIF records How to map occurence data and populations How to make a custom function for plotting figures  In this part of the tutorial, we will focus on one particular species, red deer (Cervus elaphus), where it has been recorded around the world, and where it\u0026rsquo;s populations are being monitored. We will use occurrence data from the Global Biodiversity Information Facility which we will download in R using the rgbif package.\nOccurrence data can be messy and when you are working with thousands of records, not all of them might be valid records. If you are keen to find out how to test the validity of geographic coordinates using the CoordinateCleaner package, check out our tutorial here.\n### PART 3: Downloading and mapping data from large datasets ---- #### How to map distributions and monitoring locations for one or more taxa # Packages ---- library(rgbif) # To extract GBIF data # library(CoordinateCleaner) # To clean coordinates if you want to explore that later library(gridExtra) # To make pretty graphs library(ggrepel) # To add labels with rounded edges library(png) # To add icons library(mapdata) # To plot maps library(ggthemes) # To make maps extra pretty  We are limiting the number of records to 5000 for the sake of time - in the future you can ask for more records as well, there\u0026rsquo;s just a bit of waiting involved. The records come with a lot of metadata. For our purposes, we will select just the columns we need. Similar to how before we had to specify that we want the map() function from the purrr package, there are often other select() functions, so we are saying that we want the one from dplyr using dplyr::select(). Otherwise, the select() function might not work because of a conflict with another select() function from a different package, e.g. the raster packge.\n# Download species occurrence records from the Global Biodiversity Information Facility # *** rgbif package and the occ_search() function *** # You can increase the limit to get more records - 5000 takes a couple of minutes deer.locations \u0026lt;- occ_search(scientificName = \u0026quot;Cervus elaphus\u0026quot;, limit = 5000, hasCoordinate = TRUE, return = \u0026quot;data\u0026quot;) %\u0026gt;% # Simplify occurrence data frame dplyr::select(key, name, decimalLongitude, decimalLatitude, year, individualCount, country)  Next we will extract the red deer population data - the raw time series and the slopes of population change from the two data frames.\n# Data formatting \u0026amp; manipulation ---- # Filter out population data for chosen species - red deer deer.data \u0026lt;- LPD_long2 %\u0026gt;% filter(species.name == \u0026quot;Cervus elaphus\u0026quot;) %\u0026gt;% dplyr::select(id, species.name, location.of.population, year, pop) # Filter out population estimates for chosen species - red deer deer.slopes \u0026lt;- forest.slopes %\u0026gt;% filter(species.name == \u0026quot;Cervus elaphus\u0026quot;)  In addition to making histograms, scatterplots and such, you can use ggplot2 to make maps as well - the maps come from the mapdata package we loaded earlier. In this map, we want to visualise information from two separate data frames - where the species occurs (deer.locations, the GBIF data) and where it is monitored (deer.slopes, the Living Planet Database data). We can combine this information in the same ggplot2 code chunk using the geom_point() function twice - the first time it will plot the occurrences since that the data frame associated with the plot in the very first line, and the second time we\u0026rsquo;ve told the function to specifically use the deer.slopes object using data = deer.slopes.\nAs you start making your maps, you may get this warning message:\nWarning message: In drawGrob(x) : reached elapsed time limit  We are working with thousands of records, so depending on your computer, making the map might take a while. This message doesn\u0026rsquo;t mean something is wrong, just lets you know that generating the map took a bit longer than what RStudio expected.\n# Make an occurrence map and include the locations of the populations part of the Living Planet Database (deer.map.LPD \u0026lt;- ggplot(deer.locations, aes(x = decimalLongitude, y = decimalLatitude)) + # Add map data borders(\u0026quot;world\u0026quot;, colour = \u0026quot;gray80\u0026quot;, fill = \u0026quot;gray80\u0026quot;, size = 0.3) + # Use custom map theme from ggthemes package theme_map() + # Add the points from the population change data geom_point(alpha = 0.3, size = 2, colour = \u0026quot;aquamarine3\u0026quot;) + # Specify where the data come from when plotting from more than one data frame using data = \u0026quot;\u0026quot; geom_point(data = deer.slopes, aes(x = decimal.longitude, y = decimal.latitude), size = 2, colour = \u0026quot;darkgreen\u0026quot;))   \nThe map already looks fine, but we can customise it further to add more information. For example, we can add labels for the locations of some of the monitored populations and we can add plots of population change next to our map.\nFirst we will rename some of the populations, just so that our labels are not crazy long, using the recode() function from the dplyr package.\n# Customising map to make it more beautiful ---- # Check site names print(deer.slopes$location.of.population) # Beautify site names deer.slopes$location.of.population \u0026lt;- recode(deer.slopes$location.of.population, \u0026quot;Northern Yellowstone National Park\u0026quot; = \u0026quot;Yellowstone National Park\u0026quot;) deer.slopes$location.of.population \u0026lt;- recode(deer.slopes$location.of.population, \u0026quot;Mount Rainier National Park, USA\u0026quot; = \u0026quot;Mount Rainier National Park\u0026quot;) deer.slopes$location.of.population \u0026lt;- recode(deer.slopes$location.of.population, \u0026quot;Bow Valley - eastern zone, Banff National Park, Alberta\u0026quot; = \u0026quot;Banff National Park, Alberta\u0026quot;) deer.slopes$location.of.population \u0026lt;- recode(deer.slopes$location.of.population, \u0026quot;Bow Valley - western zone, Banff National Park, Alberta\u0026quot; = \u0026quot;Banff National Park, Alberta\u0026quot;) deer.slopes$location.of.population \u0026lt;- recode(deer.slopes$location.of.population, \u0026quot;Bow Valley - central zone, Banff National Park, Alberta\u0026quot; = \u0026quot;Banff National Park, Alberta\u0026quot;) deer.slopes$location.of.population \u0026lt;- recode(deer.slopes$location.of.population, \u0026quot;Study area within Bow Valley, Banff National Park, Alberta\u0026quot; = \u0026quot;Banff National Park, Alberta\u0026quot;) deer.slopes$location.of.population \u0026lt;- recode(deer.slopes$location.of.population, \u0026quot;Bow Valley watershed of Banff National Park, Alberta\u0026quot; = \u0026quot;Banff National Park, Alberta\u0026quot;)  You can also use ggplot2 to add images to your graphs, so here we will add a deer icon.\n# Load packages for adding images packs \u0026lt;- c(\u0026quot;png\u0026quot;,\u0026quot;grid\u0026quot;) lapply(packs, require, character.only = TRUE) # Load red deer icon icon \u0026lt;- readPNG(\u0026quot;reddeer.png\u0026quot;) icon \u0026lt;- rasterGrob(icon, interpolate = TRUE)  We can update our map by adding labels and our icon - this looks like a gigantic chunk of code, but we\u0026rsquo;ve added line by line comments so that you can see what\u0026rsquo;s happening at each step. The ggrepel package adds labels whilst also aiming to avoid overlap and as a bonus, the labels have rounded edges.\n# Update map # Note - this takes a while depending on your computer (deer.map.final \u0026lt;- ggplot(deer.locations, aes(x = decimalLongitude, y = decimalLatitude)) + # For more localized maps use \u0026quot;worldHires\u0026quot; instead of \u0026quot;world\u0026quot; borders(\u0026quot;world\u0026quot;, colour = \u0026quot;gray80\u0026quot;, fill = \u0026quot;gray80\u0026quot;, size = 0.3) + theme_map() + geom_point(alpha = 0.3, size = 2, colour = \u0026quot;aquamarine3\u0026quot;) + # We are specifying the data frame for the labels - one site has three monitored populations # but we only want to label it once so we are subsetting using data = deer.slopes[c(2, 4, 5, 9),] # to get only the first rows number 2, 4, 5 and 9 geom_label_repel(data = deer.slopes[c(2, 4, 5, 9),], aes(x = decimal.longitude, y = decimal.latitude, label = location.of.population), box.padding = 1, size = 5, nudge_x = 1, # We are specifying the size of the labels and nudging the points so that they # don't hide data points, along the x axis we are nudging by one min.segment.length = 0, inherit.aes = FALSE) + # We can recreate the shape of a dropped pin by overlaying a circle and a triangle geom_point(data = deer.slopes, aes(x = decimal.longitude, y = decimal.latitude + 0.6), size = 4, colour = \u0026quot;darkgreen\u0026quot;) + geom_point(data = deer.slopes, aes(x = decimal.longitude, y = decimal.latitude - 0.3), size = 3, fill = \u0026quot;darkgreen\u0026quot;, colour = \u0026quot;darkgreen\u0026quot;, shape = 25) + # Adding the icon using the coordinates on the x and y axis annotation_custom(icon, xmin = -210, xmax = -100, ymin = -60 , ymax = -30) + # Adding a title labs(title = \u0026quot;a. Red Deer GBIF occurrences\u0026quot;, size = 12))  Let\u0026rsquo;s add some additional plots to our figure, for example how many occurrences there are for each year.\n# Visualise the number of occurrence records through time ---- # This plot is more impressive if you have downloaded more records # as GBIF downloads the most recent records first yearly.obs \u0026lt;- deer.locations %\u0026gt;% group_by(year) %\u0026gt;% tally() %\u0026gt;% ungroup() %\u0026gt;% filter(is.na(year) == FALSE) (occurrences \u0026lt;- ggplot(yearly.obs, aes(x = year, y = n)) + geom_smooth(colour = \u0026quot;aquamarine3\u0026quot;, method = 'loess', size = 1) + labs(x = NULL, y = \u0026quot;Number of occurrences\\n\u0026quot;, title = \u0026quot;b. GBIF occurrences\\n\u0026quot;, size = 12) + # Use our customised theme, saves many lines of code! theme_LPD() + # if you want to change things about your theme, you need to include the changes after adding the theme theme(plot.title = element_text(size = 12), axis.title.y = element_text(size = 10)))  We can add plots that show the population trends for those populations we\u0026rsquo;ve labelled. Given that we will be doing the same thing for multiple objects (the same type of plot for each population), we can practice functional programming and using purrr again here. The function looks very similar to a normal ggplot2 code chunk, except we\u0026rsquo;ve wrapped it up in a function and we are not using any specific objects, just x, y and z as the three arguments the function needs.\n# Visualise population trends ---- # Visualising the population trends of four deer populations # Let's practice functional programming here # *** Functional Programming *** # Let's make a function to make the population trend plots # First we need to decide what values the function needs to take # x - The population data # y - the slope value # z - the location of the monitoring # This function needs to take three arguments # Let's make the ggplot function pop.graph \u0026lt;- function(x, y, z) { # Make a ggplot graph with the 'x' ggplot(x, aes(x = year, y = pop)) + # Shape 21 chooses a point with a black outline filled with aquamarine geom_point(shape = 21, fill = \u0026quot;aquamarine3\u0026quot;, size = 2) + # Adds a linear model fit, alpha controls the transparency of the confidence intervals geom_smooth(method = \u0026quot;lm\u0026quot;, colour = \u0026quot;aquamarine3\u0026quot;, fill = \u0026quot;aquamarine3\u0026quot;, alpha = 0.4) + # Add the monitoring location 'y' into the plot labs(x = \u0026quot;\u0026quot;, y = \u0026quot;Individuals\\n\u0026quot;, title = paste(\u0026quot;c. \u0026quot;, y, \u0026quot;\\n\u0026quot;), size = 7) + # Set the y limit to the maximum population for each 'x' ylim(0, max(x$pop)) + # Set the x limit to the range of years of data xlim(1970, 2010) + # Add the slope 'y' into the plot annotate(\u0026quot;text\u0026quot;, x = 1972, y = 0, hjust = 0, vjust = -2, label = paste(\u0026quot;Slope =\u0026quot;, z), size = 3) + theme_LPD() + theme(plot.title = element_text(size=12), axis.title.y = element_text(size=10)) }  We will focus on four populations in the USA, Switzerland and Canada. We will make three objects for each population, which represent the three arguments the function takes - the population data, the slope value and the location of the population. Then we will run our function pop.graph() using those objects.\n# Find all unique ids for red deer populations unique(deer.slopes$id) # Create an object each of the unique populations # Deer population 1 - Northern Yellowstone National Park deer1 \u0026lt;- filter(deer.data, id == \u0026quot;6395\u0026quot;) slope_deer1 \u0026lt;- round(deer.slopes$estimate[deer.slopes$id == \u0026quot;6395\u0026quot;],2) location_deer1 \u0026lt;- deer.slopes$location.of.population[deer.slopes$id == \u0026quot;6395\u0026quot;] yellowstone \u0026lt;- pop.graph(deer1, location_deer1, slope_deer1) # Deer population 2 - Mount Rainier National Park, USA deer2 \u0026lt;- filter(deer.data, id == \u0026quot;3425\u0026quot;) slope_deer2 \u0026lt;- round(deer.slopes$estimate[deer.slopes$id == \u0026quot;3425\u0026quot;],2) location_deer2 \u0026lt;- deer.slopes$location.of.population[deer.slopes$id == \u0026quot;3425\u0026quot;] rainier \u0026lt;- pop.graph(deer2, location_deer2, slope_deer2) # Deer population 3 - Switzerland deer3 \u0026lt;- filter(deer.data, id == \u0026quot;11170\u0026quot;) slope_deer3 \u0026lt;- round(deer.slopes$estimate[deer.slopes$id == \u0026quot;11170\u0026quot;],2) location_deer3 \u0026lt;- deer.slopes$location.of.population[deer.slopes$id == \u0026quot;11170\u0026quot;] switzerland \u0026lt;- pop.graph(deer3, location_deer3, slope_deer3) # Deer population 4 - Banff National Park, Alberta (there are more populations here) deer4 \u0026lt;- filter(deer.data, id == \u0026quot;4383\u0026quot;) slope_deer4 \u0026lt;- round(deer.slopes$estimate[deer.slopes$id == \u0026quot;4383\u0026quot;],2) location_deer4 \u0026lt;- deer.slopes$location.of.population[deer.slopes$id == \u0026quot;4383\u0026quot;] banff \u0026lt;- pop.graph(deer4, location_deer4, slope_deer4)  We are now ready to combine all of our graphs into one panel. When using grid.arrange(), you can add an additional argument widths = c() or heights = c(), which controls the ratios between the different plots. By default, grid.arrange() will give equal space to each graph, but sometimes you might want one graph to be wider than others, like here we want the map to have more space.\n# Create panel of all graphs # Makes a panel of the map and occurrence plot and specifies the ratio # i.e., we want the map to be wider than the other plots # suppressWarnings() suppresses warnings in the ggplot call here row1 \u0026lt;- suppressWarnings(grid.arrange(deer.map.final, occurrences, ncol = 2, widths = c(1.96, 1.04))) # Makes a panel of the four population plots row2 \u0026lt;- grid.arrange(yellowstone, rainier, switzerland, banff, ncol = 4, widths = c(1, 1, 1, 1)) # Makes a panel of all the population plots and sets the ratio # Stich all of your plots together deer.panel \u0026lt;- grid.arrange(row1, row2, nrow = 2, heights = c(1.2, 0.8)) ggsave(deer.panel, filename = \u0026quot;deer_panel2.png\u0026quot;, height = 10, width = 15)   \nA challenge for later if you are keen If that wasn\u0026rsquo;t challenging enough for you, we have a challenge for you to figure out on your own. Take what you have learned about pipes and make a map for the five most well-sampled populations in the LPD database (the ones with the most replicate populations). You get extra points for incorporating a handwritten function to make the map and for using purr to implement that function.\nExtra resources You can find more info on pander here.\nTo learn more about the power of pipes check out: the tidyverse website and the R for Data Science book.\nTo learn more about purrr check out the tidyverse website and the R for Data Science book.\nFor more information on functional programming see the R for Data Science book chapter here.\nTo learn more about the tidyverse in general, check out Charlotte Wickham\u0026rsquo;s slides here.\n  \n\u0026nbsp; Subscribe to the coding club mailing list:   Subscribe     \n  \u0026nbsp;Follow our coding adventures on Twitter!     ",
    "date": 1542672000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1542672000,
    "objectID": "515ccd1595bdfcd4322bb68d474979bb",
    "permalink": "https://BES-QSIG.github.io/courses/advancingr-tidyverse/",
    "publishdate": "2018-11-20T00:00:00Z",
    "relpermalink": "/courses/advancingr-tidyverse/",
    "section": "courses",
    "summary": "PART I: Create a reproducible report using Markdown 1. What is R Markdown? R Markdown allows you to create documents that serve as a neat record of your analysis. In the world of reproducible research, we want other researchers to easily understand what we did in our analysis. You might choose to create an R markdown document as an appendix to a paper or project assignment that you are doing, upload it to an online repository such as Github, or simply to keep as a personal record so you can quickly look back at your code and see what you did.",
    "tags": null,
    "title": "Day One: Data manipulation and Visualisation using the tidyverse",
    "type": "docs"
  },
  {
    "authors": null,
    "categories": null,
    "content": "",
    "date": 1542672000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1542672000,
    "objectID": "1bc9c019a67b26a4061efc2f53012869",
    "permalink": "https://BES-QSIG.github.io/courses/advancingr-spatial/",
    "publishdate": "2018-11-20T00:00:00Z",
    "relpermalink": "/courses/advancingr-spatial/",
    "section": "courses",
    "summary": "",
    "tags": null,
    "title": "Day Two: Spatial data manipulation and visualisation in R",
    "type": "docs"
  },
  {
    "authors": null,
    "categories": null,
    "content": " The British Ecological Society Quantitative Ecology Group are hosting a two-day R workshop which will cover reproducible data manipulation and visualisation workflows in R. Day One will be focussed on the tidyverse, while Day Two will move into working with spatial data.\nDay One: Data manipulation and visualisation in R using the tidyverse Workshop leader: Gergana Daskalova, University of Edinburgh, Coding Club The tidyverse collection of packages (tidyr, dplyr, ggplot2, broom and more) is a great tool for efficient data manipulation, visualisation and analysis. In this workshop, you’ll learn how to manipulate data using pipes, build functions and apply them in a pipe, summarise model output and visualise data analysis results. We’ll then delve into functional programming using purr. Along the way, we’ll be using large ecological datasets, so you will get hands-on experience with how you can tackle big data in ecology and achieve a lot in not that many lines of code. You’ll gain skills in customising different types of graphs to maximise the impact of your data visualisation and finally, we will be doing all of this under the Markdown framework for reproducible report to promote transparency in research.\nDay Two: Spatial data manipulation and visualisation in R Workshop leader: Reto Schmucki, Centre for Ecology and Hydrology Geocomputing and manipulating geographic data are important skills for modelling spatial phenomena and have become increasingly important in data science. Over the last decade, there has been important progress in open-source GIS. In this workshop, you\u0026rsquo;ll learn how to create, import and manipulate spatial data, using the rich spatial ecosystem available in R (sf, sp, raster, tmap, leaflet). With emphasis on Simple Features for R available through the sf package. You will learn how to extract spatial information, merge complex data sets, visualise geographic data and produce interactive maps. Along the way, we\u0026rsquo;ll work on real-word data and explore how to harness the power of R and how it links to other open-source GIS solutions (QGIS, GRASS, PostGIS). At the end of this workshop, you will be able to implement a workflow to manipulate data, run analysis and visualise your results, using open-source solutions with a transparent and fully reproducible workflow.\nThe option is available to come to both days, or just one of the two. Lunch and refreshments will be provided.\nSOLD OUT\n",
    "date": 1542067200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1542067200,
    "objectID": "01f95e0909220296e198cc89ee8d497d",
    "permalink": "https://BES-QSIG.github.io/events/2018-12-3-advancing-your-r/",
    "publishdate": "2018-11-13T00:00:00Z",
    "relpermalink": "/events/2018-12-3-advancing-your-r/",
    "section": "events",
    "summary": "Want to build on your R skills for more transparant and reproducible data analysis workflows? This is the course for you!",
    "tags": [
      "R",
      "spatial",
      "tidyverse",
      "Courses"
    ],
    "title": "Advancing your R",
    "type": "events"
  }
]